{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31c51d0b",
   "metadata": {},
   "source": [
    "# Step1: Import necessary libraries\n",
    "# Data Cleaning\n",
    "# Step2: Exploratory Data Analysis\n",
    "# Step3: Data Preprocess(Scaling/Normalization and splitting the dataset)\n",
    "# Step4: Model\n",
    "# Step5: Training the model\n",
    "# Step6: Testing the model\n",
    "# Step7: Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "99cd67f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "256d75d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow.estimator as tfe\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "641c3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataset is very huge for my processor to run quickly so I reduced it. \n",
    "# Although it may affect the accuracy , it wont affect it that much"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c42f48a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('downloads/1_label.csv',nrows=50)\n",
    "df2 = pd.read_csv('downloads/2_label.csv',nrows=50)\n",
    "df3 = pd.read_csv('downloads/3_label.csv',nrows=50)\n",
    "df4 = pd.read_csv('downloads/4_label.csv',nrows=50)\n",
    "df5 = pd.read_csv('downloads/5_label.csv',nrows=50)\n",
    "df6 = pd.read_csv('downloads/6_label.csv',nrows=50)\n",
    "df7 = pd.read_csv('downloads/7_label.csv',nrows=50)\n",
    "df8 = pd.read_csv('downloads/8_label.csv',nrows=50)\n",
    "df9 = pd.read_csv('downloads/9_label.csv',nrows=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2661e207",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(449, 11)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#added all the 10 different set of data\n",
    "df = pd.concat([df1,df2,df3,df4,df5,df6,df7,df8,df9])\n",
    "df.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "05387c01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "      <th>gyr_z</th>\n",
       "      <th>mag_x</th>\n",
       "      <th>mag_y</th>\n",
       "      <th>mag_z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>1628413520</td>\n",
       "      <td>-0.385254</td>\n",
       "      <td>-0.940430</td>\n",
       "      <td>-0.077148</td>\n",
       "      <td>1.098633</td>\n",
       "      <td>-2.197266</td>\n",
       "      <td>-0.549316</td>\n",
       "      <td>-19.5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-411.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>1628413521</td>\n",
       "      <td>-0.390137</td>\n",
       "      <td>-0.935547</td>\n",
       "      <td>-0.069824</td>\n",
       "      <td>2.807617</td>\n",
       "      <td>-2.685547</td>\n",
       "      <td>-0.732422</td>\n",
       "      <td>1.5</td>\n",
       "      <td>139.5</td>\n",
       "      <td>-421.5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>1628413521</td>\n",
       "      <td>-0.392578</td>\n",
       "      <td>-0.937500</td>\n",
       "      <td>-0.073731</td>\n",
       "      <td>1.464844</td>\n",
       "      <td>-2.685547</td>\n",
       "      <td>-1.098633</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>139.5</td>\n",
       "      <td>-420.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>1628413521</td>\n",
       "      <td>-0.393555</td>\n",
       "      <td>-0.946777</td>\n",
       "      <td>-0.075684</td>\n",
       "      <td>1.953125</td>\n",
       "      <td>-2.868652</td>\n",
       "      <td>-0.854492</td>\n",
       "      <td>6.0</td>\n",
       "      <td>144.0</td>\n",
       "      <td>-420.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>1628413521</td>\n",
       "      <td>-0.384277</td>\n",
       "      <td>-0.941895</td>\n",
       "      <td>-0.076172</td>\n",
       "      <td>2.929688</td>\n",
       "      <td>-3.112793</td>\n",
       "      <td>-1.464844</td>\n",
       "      <td>-13.5</td>\n",
       "      <td>126.0</td>\n",
       "      <td>-424.5</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          time     acc_x     acc_y     acc_z     gyr_x     gyr_y     gyr_z  \\\n",
       "45  1628413520 -0.385254 -0.940430 -0.077148  1.098633 -2.197266 -0.549316   \n",
       "46  1628413521 -0.390137 -0.935547 -0.069824  2.807617 -2.685547 -0.732422   \n",
       "47  1628413521 -0.392578 -0.937500 -0.073731  1.464844 -2.685547 -1.098633   \n",
       "48  1628413521 -0.393555 -0.946777 -0.075684  1.953125 -2.868652 -0.854492   \n",
       "49  1628413521 -0.384277 -0.941895 -0.076172  2.929688 -3.112793 -1.464844   \n",
       "\n",
       "    mag_x  mag_y  mag_z  label  \n",
       "45  -19.5  126.0 -411.0      9  \n",
       "46    1.5  139.5 -421.5      9  \n",
       "47  -27.0  139.5 -420.0      9  \n",
       "48    6.0  144.0 -420.0      9  \n",
       "49  -13.5  126.0 -424.5      9  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ad0475c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['time', 'acc_x', 'acc_y', 'acc_z', 'gyr_x', 'gyr_y', 'gyr_z', 'mag_x',\n",
       "       'mag_y', 'mag_z', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "741b02a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "time     False\n",
       "acc_x    False\n",
       "acc_y    False\n",
       "acc_z    False\n",
       "gyr_x    False\n",
       "gyr_y    False\n",
       "gyr_z    False\n",
       "mag_x    False\n",
       "mag_y    False\n",
       "mag_z    False\n",
       "label    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isna().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5611564c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 12016959 entries, 0 to 98\n",
      "Data columns (total 11 columns):\n",
      " #   Column  Dtype  \n",
      "---  ------  -----  \n",
      " 0   time    int64  \n",
      " 1   acc_x   float64\n",
      " 2   acc_y   float64\n",
      " 3   acc_z   float64\n",
      " 4   gyr_x   float64\n",
      " 5   gyr_y   float64\n",
      " 6   gyr_z   float64\n",
      " 7   mag_x   float64\n",
      " 8   mag_y   float64\n",
      " 9   mag_z   float64\n",
      " 10  label   int64  \n",
      "dtypes: float64(9), int64(2)\n",
      "memory usage: 1.1 GB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "71ce2622",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>acc_x</th>\n",
       "      <th>acc_y</th>\n",
       "      <th>acc_z</th>\n",
       "      <th>gyr_x</th>\n",
       "      <th>gyr_y</th>\n",
       "      <th>gyr_z</th>\n",
       "      <th>mag_x</th>\n",
       "      <th>mag_y</th>\n",
       "      <th>mag_z</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.201696e+07</td>\n",
       "      <td>1.201696e+07</td>\n",
       "      <td>1.201696e+07</td>\n",
       "      <td>1.201696e+07</td>\n",
       "      <td>1.201696e+07</td>\n",
       "      <td>1.201696e+07</td>\n",
       "      <td>1.201696e+07</td>\n",
       "      <td>1.201696e+07</td>\n",
       "      <td>1.201696e+07</td>\n",
       "      <td>1.201696e+07</td>\n",
       "      <td>1.201696e+07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.628367e+09</td>\n",
       "      <td>-4.978357e-02</td>\n",
       "      <td>5.371257e-01</td>\n",
       "      <td>1.259089e-01</td>\n",
       "      <td>8.482040e-01</td>\n",
       "      <td>-1.868656e+00</td>\n",
       "      <td>-7.063460e-01</td>\n",
       "      <td>-2.762965e+02</td>\n",
       "      <td>4.135529e+02</td>\n",
       "      <td>2.042601e+02</td>\n",
       "      <td>4.029850e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>4.305616e+04</td>\n",
       "      <td>2.448001e-01</td>\n",
       "      <td>7.862093e-01</td>\n",
       "      <td>1.659268e-01</td>\n",
       "      <td>1.382804e+01</td>\n",
       "      <td>2.221574e+01</td>\n",
       "      <td>1.113654e+01</td>\n",
       "      <td>2.482428e+02</td>\n",
       "      <td>6.006242e+02</td>\n",
       "      <td>4.370130e+02</td>\n",
       "      <td>2.263876e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.628251e+09</td>\n",
       "      <td>-1.599756e+01</td>\n",
       "      <td>-1.599805e+01</td>\n",
       "      <td>-1.599756e+01</td>\n",
       "      <td>-1.999756e+03</td>\n",
       "      <td>-1.986816e+03</td>\n",
       "      <td>-1.969482e+03</td>\n",
       "      <td>-1.183500e+03</td>\n",
       "      <td>-7.665000e+02</td>\n",
       "      <td>-1.152000e+03</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.628328e+09</td>\n",
       "      <td>-2.216797e-01</td>\n",
       "      <td>7.900391e-01</td>\n",
       "      <td>4.541020e-02</td>\n",
       "      <td>-2.441406e+00</td>\n",
       "      <td>-6.713867e+00</td>\n",
       "      <td>-3.112793e+00</td>\n",
       "      <td>-4.140000e+02</td>\n",
       "      <td>-6.450000e+01</td>\n",
       "      <td>1.395000e+02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.628344e+09</td>\n",
       "      <td>-5.517580e-02</td>\n",
       "      <td>9.404297e-01</td>\n",
       "      <td>1.318359e-01</td>\n",
       "      <td>7.934571e-01</td>\n",
       "      <td>-1.953125e+00</td>\n",
       "      <td>-6.713868e-01</td>\n",
       "      <td>-2.310000e+02</td>\n",
       "      <td>1.095000e+02</td>\n",
       "      <td>3.240000e+02</td>\n",
       "      <td>4.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.628406e+09</td>\n",
       "      <td>1.103516e-01</td>\n",
       "      <td>9.770508e-01</td>\n",
       "      <td>2.104492e-01</td>\n",
       "      <td>4.028320e+00</td>\n",
       "      <td>2.685547e+00</td>\n",
       "      <td>1.770020e+00</td>\n",
       "      <td>-1.230000e+02</td>\n",
       "      <td>1.006500e+03</td>\n",
       "      <td>5.325000e+02</td>\n",
       "      <td>6.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.628426e+09</td>\n",
       "      <td>1.171582e+01</td>\n",
       "      <td>1.599170e+01</td>\n",
       "      <td>1.599854e+01</td>\n",
       "      <td>1.999756e+03</td>\n",
       "      <td>1.999939e+03</td>\n",
       "      <td>1.888306e+03</td>\n",
       "      <td>7.920000e+02</td>\n",
       "      <td>1.918500e+03</td>\n",
       "      <td>1.179000e+03</td>\n",
       "      <td>9.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               time         acc_x         acc_y         acc_z         gyr_x  \\\n",
       "count  1.201696e+07  1.201696e+07  1.201696e+07  1.201696e+07  1.201696e+07   \n",
       "mean   1.628367e+09 -4.978357e-02  5.371257e-01  1.259089e-01  8.482040e-01   \n",
       "std    4.305616e+04  2.448001e-01  7.862093e-01  1.659268e-01  1.382804e+01   \n",
       "min    1.628251e+09 -1.599756e+01 -1.599805e+01 -1.599756e+01 -1.999756e+03   \n",
       "25%    1.628328e+09 -2.216797e-01  7.900391e-01  4.541020e-02 -2.441406e+00   \n",
       "50%    1.628344e+09 -5.517580e-02  9.404297e-01  1.318359e-01  7.934571e-01   \n",
       "75%    1.628406e+09  1.103516e-01  9.770508e-01  2.104492e-01  4.028320e+00   \n",
       "max    1.628426e+09  1.171582e+01  1.599170e+01  1.599854e+01  1.999756e+03   \n",
       "\n",
       "              gyr_y         gyr_z         mag_x         mag_y         mag_z  \\\n",
       "count  1.201696e+07  1.201696e+07  1.201696e+07  1.201696e+07  1.201696e+07   \n",
       "mean  -1.868656e+00 -7.063460e-01 -2.762965e+02  4.135529e+02  2.042601e+02   \n",
       "std    2.221574e+01  1.113654e+01  2.482428e+02  6.006242e+02  4.370130e+02   \n",
       "min   -1.986816e+03 -1.969482e+03 -1.183500e+03 -7.665000e+02 -1.152000e+03   \n",
       "25%   -6.713867e+00 -3.112793e+00 -4.140000e+02 -6.450000e+01  1.395000e+02   \n",
       "50%   -1.953125e+00 -6.713868e-01 -2.310000e+02  1.095000e+02  3.240000e+02   \n",
       "75%    2.685547e+00  1.770020e+00 -1.230000e+02  1.006500e+03  5.325000e+02   \n",
       "max    1.999939e+03  1.888306e+03  7.920000e+02  1.918500e+03  1.179000e+03   \n",
       "\n",
       "              label  \n",
       "count  1.201696e+07  \n",
       "mean   4.029850e+00  \n",
       "std    2.263876e+00  \n",
       "min    1.000000e+00  \n",
       "25%    1.000000e+00  \n",
       "50%    4.000000e+00  \n",
       "75%    6.000000e+00  \n",
       "max    9.000000e+00  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bcd4dd2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 12 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#some graph to show relationship ammong variables\n",
    "df.hist()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "933d9e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7fd89fce02e0>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(df['label'],df['time'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "04515525",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#data preprocessing\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(df.drop(\"label\",axis=1))\n",
    "scaler = scaler.fit_transform(df.drop(\"label\",axis=1))\n",
    "scaler = pd.DataFrame(scaler,columns=['time', 'acc_x', 'acc_y', 'acc_z', 'gyr_x', 'gyr_y', 'gyr_z', 'mag_x',\n",
    "       'mag_y', 'mag_z'])\n",
    "\n",
    "\n",
    "X = scaler.loc[:,:]\n",
    "y = df.loc[:,'label']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "fd035fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b9cb79d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow requires feature column so it will know wether is is dealing with numbers or categorical values\n",
    "def feature_columns():\n",
    "    \n",
    "    feat_time = tf.feature_column.numeric_column('time')\n",
    "    feat_acc_x = tf.feature_column.numeric_column('acc_x')\n",
    "    feat_acc_y = tf.feature_column.numeric_column('acc_y')\n",
    "    feat_acc_z = tf.feature_column.numeric_column('acc_z')\n",
    "    feat_gyr_x = tf.feature_column.numeric_column('gyr_x')\n",
    "    feat_gyr_y = tf.feature_column.numeric_column('gyr_y')\n",
    "    feat_gyr_z  = tf.feature_column.numeric_column('gyr_z')\n",
    "    feat_mag_x  = tf.feature_column.numeric_column('mag_x')\n",
    "    feat_mag_y  = tf.feature_column.numeric_column('mag_y')\n",
    "    feat_mag_z  = tf.feature_column.numeric_column('mag_z')\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    feature_column = ['feat_time', 'feat_acc_x', 'feat_acc_y', 'feat_acc_z', 'feat_gyr_x', 'feat_gyr_y',\n",
    "                      'feat_gyr_z', 'feat_mag_x','feat_mag_y', 'feat_mag_z']\n",
    "    return feature_column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "00667c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "input_func = tf.compat.v1.estimator.inputs.pandas_input_fn(X_train, \n",
    "                                                 y_train,\n",
    "                                                 batch_size=100,\n",
    "                                                 num_epochs=1000,\n",
    "                                                 shuffle=True)\n",
    "\n",
    "eval_func = tf.compat.v1.estimator.inputs.pandas_input_fn(X_test,\n",
    "                                               y_test,\n",
    "                                               batch_size=100,\n",
    "                                               num_epochs=1,\n",
    "                                               shuffle=False)\n",
    "predict_input_fn = tf.compat.v1.estimator.inputs.pandas_input_fn(\n",
    "      x=X_test,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4a0871da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/w6/sqx_mjh176x08sjppl82f1l80000gn/T/tmpd7azes74\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/w6/sqx_mjh176x08sjppl82f1l80000gn/T/tmpd7azes74', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_checkpoint_save_graph_def': True, '_service': None, '_cluster_spec': ClusterSpec({}), '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "feature_column = feature_columns()\n",
    "classifier = tfe.DNNClassifier(\n",
    "    feature_columns=feature_column,\n",
    "    hidden_units=[1024, 512, 256],\n",
    "    n_classes=10,\n",
    "    optimizer = tf.optimizers.Adam(learning_rate=0.3))\n",
    "    \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eff747e9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Received a feature column from TensorFlow v1, but this is a TensorFlow v2 Estimator. Please either use v2 feature columns (accessible via tf.feature_column.* in TF 2.x) with this Estimator, or switch to a v1 Estimator for use with v1 feature columns (accessible via tf.compat.v1.estimator.* and tf.compat.v1.feature_column.*, respectively.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-867198c0dd30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = classifier.train(input_fn=input_fn, \n\u001b[0m\u001b[1;32m      2\u001b[0m                steps=500)\n\u001b[1;32m      3\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, input_fn, hooks, steps, max_steps, saving_listeners)\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    348\u001b[0m       \u001b[0msaving_listeners\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_listeners_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m       \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Loss for final step: %s.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1173\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_distributed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_train_model_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msaving_listeners\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_train_model_default\u001b[0;34m(self, input_fn, hooks, saving_listeners)\u001b[0m\n\u001b[1;32m   1201\u001b[0m           self._get_features_and_labels_from_input_fn(input_fn, ModeKeys.TRAIN))\n\u001b[1;32m   1202\u001b[0m       \u001b[0mworker_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_hooks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1203\u001b[0;31m       estimator_spec = self._call_model_fn(features, labels, ModeKeys.TRAIN,\n\u001b[0m\u001b[1;32m   1204\u001b[0m                                            self.config)\n\u001b[1;32m   1205\u001b[0m       \u001b[0mglobal_step_tensor\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_global_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1162\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1163\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1164\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_model_fn\u001b[0;34m(features, labels, mode, config)\u001b[0m\n\u001b[1;32m    748\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m       \u001b[0;34m\"\"\"Call the defined shared dnn_model_fn_v2.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m       return dnn_model_fn_v2(\n\u001b[0m\u001b[1;32m    751\u001b[0m           \u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m           \u001b[0mlabels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36mdnn_model_fn_v2\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    558\u001b[0m   \u001b[0;32mdel\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m   logits, trainable_variables, update_ops = _dnn_model_fn_builder_v2(\n\u001b[0m\u001b[1;32m    561\u001b[0m       \u001b[0munits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogits_dimension\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m       \u001b[0mhidden_units\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_units\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m_dnn_model_fn_builder_v2\u001b[0;34m(units, hidden_units, feature_columns, activation_fn, dropout, batch_norm, features, mode)\u001b[0m\n\u001b[1;32m    494\u001b[0m     raise ValueError('units must be an int.  Given type: {}'.format(\n\u001b[1;32m    495\u001b[0m         type(units)))\n\u001b[0;32m--> 496\u001b[0;31m   dnn_model = _DNNModelV2(\n\u001b[0m\u001b[1;32m    497\u001b[0m       \u001b[0munits\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    498\u001b[0m       \u001b[0mhidden_units\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow_estimator/python/estimator/canned/dnn.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, units, hidden_units, feature_columns, activation_fn, dropout, batch_norm, name, **kwargs)\u001b[0m\n\u001b[1;32m    294\u001b[0m             feature_columns=feature_columns, name=layer_name)\n\u001b[1;32m    295\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m    297\u001b[0m             \u001b[0;34m'Received a feature column from TensorFlow v1, but this is a '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;34m'TensorFlow v2 Estimator. Please either use v2 feature columns '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Received a feature column from TensorFlow v1, but this is a TensorFlow v2 Estimator. Please either use v2 feature columns (accessible via tf.feature_column.* in TF 2.x) with this Estimator, or switch to a v1 Estimator for use with v1 feature columns (accessible via tf.compat.v1.estimator.* and tf.compat.v1.feature_column.*, respectively."
     ]
    }
   ],
   "source": [
    "train = classifier.train(input_fn=input_fn, \n",
    "               steps=500)\n",
    "train\n",
    "\n",
    "\n",
    "#I keep on getting this error because I am not that familiar with tensorflow\n",
    "# and Ive done a lot of research but none helped me\n",
    "#so I tried a different model(Sequential) instead of DNNClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3071bacc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "12/12 [==============================] - 1s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0787\n",
      "Epoch 2/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1004\n",
      "Epoch 3/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1019\n",
      "Epoch 4/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1065\n",
      "Epoch 5/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1034\n",
      "Epoch 6/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0997\n",
      "Epoch 7/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1015\n",
      "Epoch 8/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1137\n",
      "Epoch 9/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0961\n",
      "Epoch 10/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1023\n",
      "Epoch 11/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0931\n",
      "Epoch 12/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1010\n",
      "Epoch 13/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1011\n",
      "Epoch 14/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1119\n",
      "Epoch 15/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1059\n",
      "Epoch 16/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.0899\n",
      "Epoch 17/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1024\n",
      "Epoch 18/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0835\n",
      "Epoch 19/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1053\n",
      "Epoch 20/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0883\n",
      "Epoch 21/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1115\n",
      "Epoch 22/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1083\n",
      "Epoch 23/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0951\n",
      "Epoch 24/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0903\n",
      "Epoch 25/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0883\n",
      "Epoch 26/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0851\n",
      "Epoch 27/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1113\n",
      "Epoch 28/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1047\n",
      "Epoch 29/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1097\n",
      "Epoch 30/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1084\n",
      "Epoch 31/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0999\n",
      "Epoch 32/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0983\n",
      "Epoch 33/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1082\n",
      "Epoch 34/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1015\n",
      "Epoch 35/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1081\n",
      "Epoch 36/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1165\n",
      "Epoch 37/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1002\n",
      "Epoch 38/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1141\n",
      "Epoch 39/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1088\n",
      "Epoch 40/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0975\n",
      "Epoch 41/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1061\n",
      "Epoch 42/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0964\n",
      "Epoch 43/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1166\n",
      "Epoch 44/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1208\n",
      "Epoch 45/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1000\n",
      "Epoch 46/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1006\n",
      "Epoch 47/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1060\n",
      "Epoch 48/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0974\n",
      "Epoch 49/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1084\n",
      "Epoch 50/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0971\n",
      "Epoch 51/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1087\n",
      "Epoch 52/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1207\n",
      "Epoch 53/400\n",
      "12/12 [==============================] - 0s 4ms/step - loss: 0.0000e+00 - accuracy: 0.1000\n",
      "Epoch 54/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0969\n",
      "Epoch 55/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1093\n",
      "Epoch 56/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1062\n",
      "Epoch 57/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0944\n",
      "Epoch 58/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1325\n",
      "Epoch 59/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0951\n",
      "Epoch 60/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1024\n",
      "Epoch 61/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0994\n",
      "Epoch 62/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0930\n",
      "Epoch 63/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1101\n",
      "Epoch 64/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1070\n",
      "Epoch 65/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0939\n",
      "Epoch 66/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0940\n",
      "Epoch 67/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1094\n",
      "Epoch 68/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1187\n",
      "Epoch 69/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1169\n",
      "Epoch 70/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0961\n",
      "Epoch 71/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1005\n",
      "Epoch 72/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1061\n",
      "Epoch 73/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1117\n",
      "Epoch 74/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0982\n",
      "Epoch 75/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1074\n",
      "Epoch 76/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0952\n",
      "Epoch 77/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1372\n",
      "Epoch 78/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0985\n",
      "Epoch 79/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1100\n",
      "Epoch 80/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1163\n",
      "Epoch 81/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1037\n",
      "Epoch 82/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0912\n",
      "Epoch 83/400\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.0929\n",
      "Epoch 84/400\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.0951\n",
      "Epoch 85/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1088\n",
      "Epoch 86/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1121\n",
      "Epoch 87/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1110\n",
      "Epoch 88/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0886\n",
      "Epoch 89/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1153\n",
      "Epoch 90/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0984\n",
      "Epoch 91/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1284\n",
      "Epoch 92/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1115\n",
      "Epoch 93/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1020\n",
      "Epoch 94/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1087\n",
      "Epoch 95/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1050\n",
      "Epoch 96/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0905\n",
      "Epoch 97/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1246\n",
      "Epoch 98/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1048\n",
      "Epoch 99/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1234\n",
      "Epoch 100/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1145\n",
      "Epoch 101/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0985\n",
      "Epoch 102/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1088\n",
      "Epoch 103/400\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1072\n",
      "Epoch 104/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1201\n",
      "Epoch 105/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1101\n",
      "Epoch 106/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1047\n",
      "Epoch 107/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1172\n",
      "Epoch 108/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1292\n",
      "Epoch 109/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0989\n",
      "Epoch 110/400\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1083\n",
      "Epoch 111/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0894\n",
      "Epoch 112/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1223\n",
      "Epoch 113/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1311\n",
      "Epoch 114/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1011\n",
      "Epoch 115/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1034\n",
      "Epoch 116/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1140\n",
      "Epoch 117/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1187\n",
      "Epoch 118/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0917\n",
      "Epoch 119/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0981\n",
      "Epoch 120/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1176\n",
      "Epoch 121/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1114\n",
      "Epoch 122/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0995\n",
      "Epoch 123/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0915\n",
      "Epoch 124/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0970\n",
      "Epoch 125/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0974\n",
      "Epoch 126/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1117\n",
      "Epoch 127/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1060\n",
      "Epoch 128/400\n",
      "12/12 [==============================] - ETA: 0s - loss: 0.0000e+00 - accuracy: 0.06 - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1029\n",
      "Epoch 129/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1284\n",
      "Epoch 130/400\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.0970\n",
      "Epoch 131/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1031\n",
      "Epoch 132/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0926\n",
      "Epoch 133/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0984\n",
      "Epoch 134/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1121\n",
      "Epoch 135/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0957\n",
      "Epoch 136/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1060\n",
      "Epoch 137/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1028\n",
      "Epoch 138/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1081\n",
      "Epoch 139/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1276\n",
      "Epoch 140/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1177\n",
      "Epoch 141/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1035\n",
      "Epoch 142/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1261\n",
      "Epoch 143/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1280\n",
      "Epoch 144/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0974\n",
      "Epoch 145/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1248\n",
      "Epoch 146/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1200\n",
      "Epoch 147/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1175\n",
      "Epoch 148/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1028\n",
      "Epoch 149/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0944\n",
      "Epoch 150/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1061\n",
      "Epoch 151/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1197\n",
      "Epoch 152/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1322\n",
      "Epoch 153/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1009\n",
      "Epoch 154/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0957\n",
      "Epoch 155/400\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.0938\n",
      "Epoch 156/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1002\n",
      "Epoch 157/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1170\n",
      "Epoch 158/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1136\n",
      "Epoch 159/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1110\n",
      "Epoch 160/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.0777\n",
      "Epoch 161/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0841\n",
      "Epoch 162/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1148\n",
      "Epoch 163/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0810\n",
      "Epoch 164/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1064\n",
      "Epoch 165/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0999\n",
      "Epoch 166/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0932\n",
      "Epoch 167/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1063\n",
      "Epoch 168/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1061\n",
      "Epoch 169/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1103\n",
      "Epoch 170/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1275\n",
      "Epoch 171/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1244\n",
      "Epoch 172/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1009\n",
      "Epoch 173/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1271\n",
      "Epoch 174/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0967\n",
      "Epoch 175/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1202\n",
      "Epoch 176/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0986\n",
      "Epoch 177/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1104\n",
      "Epoch 178/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1115\n",
      "Epoch 179/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0949\n",
      "Epoch 180/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0826\n",
      "Epoch 181/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1156\n",
      "Epoch 182/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1213\n",
      "Epoch 183/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0944\n",
      "Epoch 184/400\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.1210\n",
      "Epoch 185/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0855\n",
      "Epoch 186/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1109\n",
      "Epoch 187/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1178\n",
      "Epoch 188/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1003\n",
      "Epoch 189/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1086\n",
      "Epoch 190/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1119\n",
      "Epoch 191/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1182\n",
      "Epoch 192/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1111\n",
      "Epoch 193/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0872\n",
      "Epoch 194/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1060\n",
      "Epoch 195/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1068\n",
      "Epoch 196/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1182\n",
      "Epoch 197/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0944\n",
      "Epoch 198/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1122\n",
      "Epoch 199/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0951\n",
      "Epoch 200/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1158\n",
      "Epoch 201/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1174\n",
      "Epoch 202/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1294\n",
      "Epoch 203/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0966\n",
      "Epoch 204/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1169\n",
      "Epoch 205/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1069\n",
      "Epoch 206/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1309\n",
      "Epoch 207/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1017\n",
      "Epoch 208/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1136\n",
      "Epoch 209/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1102\n",
      "Epoch 210/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1012\n",
      "Epoch 211/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0897\n",
      "Epoch 212/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1155\n",
      "Epoch 213/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1004\n",
      "Epoch 214/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1069\n",
      "Epoch 215/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1091\n",
      "Epoch 216/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1034\n",
      "Epoch 217/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1130\n",
      "Epoch 218/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1142\n",
      "Epoch 219/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1014\n",
      "Epoch 220/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1034\n",
      "Epoch 221/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1283\n",
      "Epoch 222/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0961\n",
      "Epoch 223/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1096\n",
      "Epoch 224/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1192\n",
      "Epoch 225/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0947\n",
      "Epoch 226/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1224\n",
      "Epoch 227/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1042\n",
      "Epoch 228/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1156\n",
      "Epoch 229/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1170\n",
      "Epoch 230/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1033\n",
      "Epoch 231/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0923\n",
      "Epoch 232/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1099\n",
      "Epoch 233/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1045\n",
      "Epoch 234/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0817\n",
      "Epoch 235/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0966\n",
      "Epoch 236/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0914\n",
      "Epoch 237/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1005\n",
      "Epoch 238/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0896\n",
      "Epoch 239/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0932\n",
      "Epoch 240/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0967\n",
      "Epoch 241/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1074\n",
      "Epoch 242/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1086\n",
      "Epoch 243/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0930\n",
      "Epoch 244/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1097\n",
      "Epoch 245/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0997\n",
      "Epoch 246/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1096\n",
      "Epoch 247/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0924\n",
      "Epoch 248/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1185\n",
      "Epoch 249/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0928\n",
      "Epoch 250/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0923\n",
      "Epoch 251/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1265\n",
      "Epoch 252/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1295\n",
      "Epoch 253/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1252\n",
      "Epoch 254/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1061\n",
      "Epoch 255/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1103\n",
      "Epoch 256/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0935\n",
      "Epoch 257/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0993\n",
      "Epoch 258/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1114\n",
      "Epoch 259/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0976\n",
      "Epoch 260/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1199\n",
      "Epoch 261/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1146\n",
      "Epoch 262/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1087\n",
      "Epoch 263/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1177\n",
      "Epoch 264/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0818\n",
      "Epoch 265/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1029\n",
      "Epoch 266/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1267\n",
      "Epoch 267/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0897\n",
      "Epoch 268/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1147\n",
      "Epoch 269/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1082\n",
      "Epoch 270/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1222\n",
      "Epoch 271/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1222\n",
      "Epoch 272/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1206\n",
      "Epoch 273/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1068\n",
      "Epoch 274/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1184\n",
      "Epoch 275/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1208\n",
      "Epoch 276/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1292\n",
      "Epoch 277/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1222\n",
      "Epoch 278/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0827\n",
      "Epoch 279/400\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.0000e+00 - accuracy: 0.1160\n",
      "Epoch 280/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1057\n",
      "Epoch 281/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1011\n",
      "Epoch 282/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0904\n",
      "Epoch 283/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1119\n",
      "Epoch 284/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0936\n",
      "Epoch 285/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1127\n",
      "Epoch 286/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1207\n",
      "Epoch 287/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1116\n",
      "Epoch 288/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0832\n",
      "Epoch 289/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0910\n",
      "Epoch 290/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1162\n",
      "Epoch 291/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1170\n",
      "Epoch 292/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1103\n",
      "Epoch 293/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1265\n",
      "Epoch 294/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0999\n",
      "Epoch 295/400\n",
      "12/12 [==============================] - 0s 1ms/step - loss: 0.0000e+00 - accuracy: 0.0957\n",
      "Epoch 296/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0977\n",
      "Epoch 297/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1019\n",
      "Epoch 298/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1120\n",
      "Epoch 299/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1064\n",
      "Epoch 300/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0948\n",
      "Epoch 301/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1148\n",
      "Epoch 302/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1181\n",
      "Epoch 303/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1033\n",
      "Epoch 304/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1190\n",
      "Epoch 305/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1043\n",
      "Epoch 306/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1205\n",
      "Epoch 307/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1140\n",
      "Epoch 308/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1107\n",
      "Epoch 309/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0986\n",
      "Epoch 310/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0923\n",
      "Epoch 311/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1186\n",
      "Epoch 312/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0938\n",
      "Epoch 313/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1107\n",
      "Epoch 314/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1304\n",
      "Epoch 315/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1007\n",
      "Epoch 316/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1156\n",
      "Epoch 317/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0987\n",
      "Epoch 318/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1204\n",
      "Epoch 319/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1006\n",
      "Epoch 320/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0962\n",
      "Epoch 321/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0918\n",
      "Epoch 322/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1138\n",
      "Epoch 323/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1292\n",
      "Epoch 324/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1235\n",
      "Epoch 325/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0987\n",
      "Epoch 326/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1204\n",
      "Epoch 327/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1108\n",
      "Epoch 328/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1138\n",
      "Epoch 329/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1131\n",
      "Epoch 330/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1000\n",
      "Epoch 331/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1039\n",
      "Epoch 332/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1048\n",
      "Epoch 333/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1045\n",
      "Epoch 334/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1109\n",
      "Epoch 335/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0831\n",
      "Epoch 336/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0895\n",
      "Epoch 337/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0876\n",
      "Epoch 338/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1308\n",
      "Epoch 339/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1056\n",
      "Epoch 340/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1108\n",
      "Epoch 341/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1199\n",
      "Epoch 342/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1067\n",
      "Epoch 343/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0915\n",
      "Epoch 344/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1235\n",
      "Epoch 345/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0987\n",
      "Epoch 346/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0755\n",
      "Epoch 347/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1156\n",
      "Epoch 348/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0984\n",
      "Epoch 349/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0888\n",
      "Epoch 350/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1341\n",
      "Epoch 351/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1017\n",
      "Epoch 352/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1059\n",
      "Epoch 353/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0918\n",
      "Epoch 354/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1200\n",
      "Epoch 355/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1118\n",
      "Epoch 356/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1164\n",
      "Epoch 357/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1154\n",
      "Epoch 358/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0953\n",
      "Epoch 359/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1028\n",
      "Epoch 360/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0973\n",
      "Epoch 361/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1069\n",
      "Epoch 362/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1010\n",
      "Epoch 363/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1048\n",
      "Epoch 364/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1079\n",
      "Epoch 365/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0902\n",
      "Epoch 366/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1113\n",
      "Epoch 367/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1226\n",
      "Epoch 368/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0839\n",
      "Epoch 369/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1191\n",
      "Epoch 370/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1265\n",
      "Epoch 371/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1120\n",
      "Epoch 372/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0975\n",
      "Epoch 373/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1006\n",
      "Epoch 374/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0937\n",
      "Epoch 375/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1275\n",
      "Epoch 376/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1063\n",
      "Epoch 377/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1127\n",
      "Epoch 378/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1221\n",
      "Epoch 379/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1175\n",
      "Epoch 380/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0872\n",
      "Epoch 381/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0927\n",
      "Epoch 382/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0983\n",
      "Epoch 383/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0844\n",
      "Epoch 384/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1114\n",
      "Epoch 385/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1074\n",
      "Epoch 386/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0953\n",
      "Epoch 387/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1129\n",
      "Epoch 388/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1136\n",
      "Epoch 389/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0981\n",
      "Epoch 390/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1126\n",
      "Epoch 391/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1083\n",
      "Epoch 392/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1063\n",
      "Epoch 393/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1083\n",
      "Epoch 394/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1098\n",
      "Epoch 395/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1040\n",
      "Epoch 396/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1111\n",
      "Epoch 397/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1019\n",
      "Epoch 398/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.0938\n",
      "Epoch 399/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1060\n",
      "Epoch 400/400\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.0000e+00 - accuracy: 0.1241\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fefa6173700>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#using Sequential Model on the dataset\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(64,activation='relu',input_dim=10))\n",
    "model.add(Dense(32,activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(1,activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',loss='categorical_crossentropy',metrics = ['accuracy'])\n",
    "\n",
    "model.fit(X_train,y_train,epochs=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a06d5c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "## I will work on this data again\n",
    "## I am still learning 🙏🏻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de199d0e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
